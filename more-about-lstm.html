
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Повеќе за LSTM &#8212; Recurrent neural networks with LSTM as focus</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Markdown Files" href="markdown.html" />
    <link rel="prev" title="Потребата од LSTM" href="lstm-as-solution.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      <img src="_static/lstm-operations.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Recurrent neural networks with LSTM as focus</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="content.html">
   Содржина
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="motivation.html">
   Мотивација
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Вовед
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lstm-as-solution.html">
   Потребата од LSTM
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Повеќе за LSTM
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="markdown.html">
   Markdown Files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notebooks.html">
   Content with notebooks
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/more-about-lstm.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fmore-about-lstm.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Концептот на LSTM
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   Сигмоиди
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   Порти кај LSTM
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#python-lstm">
   Python псевдо код за LSTM
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="lstm">
<h1>Повеќе за LSTM<a class="headerlink" href="#lstm" title="Permalink to this headline">¶</a></h1>
<p>LSTM имаат сличен flow како и RNN. Процесираат податоци и пренесуваат информација како што пропагираат нанапред. Разликата од RNN е во однос на операциите кои се извршуваат во ќелиите на LSTM.</p>
<p><img alt="lstm-operations" src="_images/lstm-operations.png" /></p>
<p>Ова се операциите кои овозможуваат на LSTM да чува или да заборава информации.</p>
<div class="section" id="id1">
<h2>Концептот на LSTM<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>Главниот концепт на LSTM мрежите е состојбата на ќелијата и портите кои се содржат во учеството на нејзиното регулирање. Таа пренесува информации понатаму низ веригата на секвенци кои се случуваат. На некој начин таа е ‘меморија’ на мрежата. Таа пренесува информации не само од последната секвенца, туку и од претходните временски чекори кои биле сметани за потребни, со тоа спротиставувајќи му се на проблемот со краткорајна меморија кои го имаат RNN. Низ целото ‘патување’ на неа се додаваат или одземаат информации преку портите кои го одлучуваат тоа, што ќе дозволат да остане, што ќе се ‘заборави’. Портите, при процесот на тоа одлучување, дејствуваат како засебни невронски мрежи.</p>
</div>
<div class="section" id="id2">
<h2>Сигмоиди<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>Портите содржат сигмоидни активации. Сигмоидна активација е слична на концептот на tanh активацијата која беше пресудна кај RNN. Разликата е што влезните вредности се нормализираат во рангот помеѓу 0 и 1. Ова овозможува да се зачува или да се ‘заборави’ информација, бидејќи множењето со вредности блиски или еднакви до 1 помага да се зачува таа информација, додека множењето со вредности кои се стремат кон 0 предизвикува вредноста да ја снема, односно да се заборави. Така LSTM мрежите одлучуваат кои податоци се важни за да се зачуваат, а кои не и може да се ‘заборават’.</p>
</div>
<div class="section" id="id3">
<h2>Порти кај LSTM<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>Секоја LSTM мрежа има три различни порти кои го регулираат протокот на информации:</p>
<ul>
<li><p><strong>Input порта</strong></p>
<p>Нејзината цел е избор кои(и колку) од <strong>новите информации</strong> ќе бидат зачувани во <strong>долготрајната меморија</strong>. Во неа влегуваат претходниот hidden state и моменталниот влез кои се предаваат на сигмоидна активација. Така се одлучува кои вредности ќе бидат пренесени преку нивна трансформација во 0(ќе биде заборавена) или 1(ќе биде пренесена). Истиот процес се случува и предавање во tanh функција, која има и своја сигмоидна активација која одлучува колкав дел од излезот од неа ќе биде зачуван преку операцијата на множење која се извршува.</p>
<p><img alt="input-gate" src="_images/input_gate.jpg" /></p>
<p>Математички ова е постигнато со користење на два слоеви:</p>
<ul class="simple">
<li><p>Првиот може да се претстави со формула:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
  i_1=σ(W_{i_1}⋅(H_{t−1}, x_t)+bias_{i_1})
  \]</div>
<p>Како слојот е трениран со помош на <em>back-propagation</em>, тежините во сигмоидната функција ќе бидат обновени така што истиот ќе научи да ги пропушта само корисните работи да поминат понатаму, притоа отфрлајќи ги помалку корисните својства.</p>
<ul class="simple">
<li><p>Вториот може да се претстави исто така со формула:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
  i_2=tanh(W{i_2}⋅(H_{t−1}, x_t)+bias_{i_2})
  \]</div>
<p>Како што објаснивме, тука е делот со кој се врши регулација на мрежата.</p>
<p>Излезот од нивната комбинација е влезот во самата Input порта, односно информацијата која ќе биде зачувана во меморијата:</p>
<div class="math notranslate nohighlight">
\[
  i_{input}=i_1∗i_2
  \]</div>
</li>
<li><p><strong>Forget порта</strong></p>
<p>Forget портата служи како <strong>регулација</strong> кои информации од долготрајната меморија ќе бидат зачувани, а кои отфрлени. Се дефинира преку состојбата од претходната ќелија, на која преку множење со forget векторот се пресметува дали и колку од таа информација ќе остане, како и собирањето на излез вредноста на tanh функција со forget векторот применет на неа, каде се пресметува дали и колку од новата информација ќе биде зачувана. Преку собирање на двете компоненти се добива новата состојба на ќелијата(долготрајната меморија).</p>
<p><img alt="forget-gate" src="_images/forget_gate.jpg" /></p>
<p>Математички ќе го претставиме тоа на следниот начин:</p>
<div class="math notranslate nohighlight">
\[
  f=σ(W_{forget}⋅(H_{t−1}, x_t)+bias_{forget})
  \]</div>
<p>Функција слична на слојот од Input портата, со тоа што, во овој случај, тежините се различни.</p>
<div class="math notranslate nohighlight">
\[
  C_t=C_{t−1}∗f+i_{input}
  \]</div>
<p>Излезот од претходната функција(forget векторот) се множи со долготрајната меморија и избира кои делови од истата ќе бидат зачувани. На тој резултат се додава излезот од Input портата кој го објаснивме, односно новата информација која што е одлучено да се додаде кон долготрајната меморија. Резултатот од ова се предава понатаму на Output портата.</p>
</li>
<li><p><strong>Output порта</strong></p>
<p>Ја одлучува следната hidden state преку предавање на новата состојба на ќелијата во tanh функција и нејзино множење со forget векторот. Врз двете влезни компоненти потоа се врши множење. Резултатот, следната hidden state, потоа се предава понатаму за користење како информација за претходните влезови при натамошно предвидување.</p>
<p><img alt="output-gate" src="_images/output_gate.jpg" /></p>
<p>Математички претставено преку формули изгледа следно:</p>
<div class="math notranslate nohighlight">
\[
  O_1=σ(W_{output_1}⋅(H_{t−1}, x_t)+bias_{output_1})
  \]</div>
<div class="math notranslate nohighlight">
\[
  O_2=tanh(W_{output_2}⋅C_t+bias_{output_2})
  \]</div>
<div class="math notranslate nohighlight">
\[
  H_t,O_t=O_1∗O_2
  \]</div>
<p>Излезите, односно hidden state-от и долготрајната меморија(состојбата на ќелијата) се предадени кон следната итерација на процесот. Излезот од конкретната итерација може да се добие преку hidden state-от.</p>
</li>
</ul>
</div>
<div class="section" id="python-lstm">
<h2>Python псевдо код за LSTM<a class="headerlink" href="#python-lstm" title="Permalink to this headline">¶</a></h2>
<p><img alt="pseudo-code" src="_images/pseudo-code.png" /></p>
<p>Кодот опишан на кратко би бил for циклус и неколку функциски операции. кои враќаат следни состојба на ќелија и hidden state. Преку комбинирање на тие неколку функциски операции LSTM мрежата бира кои информации се од важност за да се пренесат или да се ‘заборават’ при процесирањето на секвенците.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="lstm-as-solution.html" title="previous page">Потребата од LSTM</a>
    <a class='right-next' id="next-link" href="markdown.html" title="next page">Markdown Files</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Roberto Kostov<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>